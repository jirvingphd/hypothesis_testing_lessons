{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZM6DyjYckZl2"
   },
   "source": [
    "\n",
    "# Section 22: Hypothesis Testing ( A/B Testing) In-Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EM8QVDhSUCa_"
   },
   "source": [
    "- online-ds-pt-100719\n",
    "- For 01/28/20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BWefqzWJoc_E"
   },
   "source": [
    "# Topics \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Study Group Thursday after speaker**\n",
    "- Revisiting workflow: choosing the correct hypothesis test.\n",
    "\n",
    "- Apply workflow to [\"In-Depth AB Testing Lab\"](https://learn.co/tracks/data-science-career-v2/module-3-probability-sampling-and-ab-testing/section-22-ab-testing/in-depth-ab-testing-lab)\n",
    "\n",
    "- Perform post-hoc calculations and write conclusions:\n",
    "    - Effect Size\n",
    "    - Post-hoc pairwise comparisons \n",
    "    - [Statistical Power](https://rpsychologist.com/d3/NHST/)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions/Insights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AB Testing Lab Simplified\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "**Overivews/Cheatsheets**\n",
    "- [CodeAcademy Hypothesis Testing Slideshow](https://drive.google.com/open?id=1p4R2KCErq_iUO-wnfDrGPukTgQDBNoc7)\n",
    "- [Cheatsheet: Hypothesis Testing with Scipy](https://drive.google.com/open?id=1EY4UCg20HawWlWa50M2tFauoKBQcFFAW)\n",
    "\n",
    "\n",
    "- [Choosing Between Parametric and Non-Parametric Tests](https://blog.minitab.com/blog/adventures-in-statistics-2/choosing-between-a-nonparametric-test-and-a-parametric-test)\n",
    "\n",
    "**Trustable Stat References**:\n",
    "- [Graphpad Prism's Stat Guide](https://www.graphpad.com/guides/prism/8/statistics/index.htm)\n",
    "- [LAERD Statistics Test Selector](https://statistics.laerd.com/premium/sts/index.php)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the Correct Hypothesis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  STEP 0: Stating our Hypothesis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Before selecting the correct hypothesis test, you must first officially state your null hypothesis ($H_0$) and alternative hypothesis ($H_A$ or $H_1$)**\n",
    "\n",
    "> **Before stating your hypotheses, ask yourself:**\n",
    "1. What question am I attempting to answer?\n",
    "2. What metric/value do I want to measure to answer this question?\n",
    "3. Do I expect the groups to be different in a specific way? (i.e. one group greater than the other).\n",
    "    - Or do I just think they'll be different, but don't know how?\n",
    "\n",
    "- **Now formally declare your hypotheses after asking yourself the questions above:**\n",
    "\n",
    "- $H_1$ : \n",
    "\n",
    "- $H_0$ :\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Determine the category/type of test based on your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: What type of data do I have (Numeric or categorical?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: How many samples/groups am I comparing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the answers to the above 2 questions: select the type of test from this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| What type of comparison? | Numeric Data | Categorical Data|\n",
    "| --- | --- | --- |\n",
    "|Sample vs Known Quantity/Target|1 Sample T-Test| Binomial Test|\n",
    "|2 Samples | 2 Sample T-Test| Chi-Square|\n",
    "|More than 2| ANOVA and/or Tukey | Chi Square|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2:  Do we meet the assumptions of the chosen test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSUMPTIONS SUMMARY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [One-Sample T-Test](https://statistics.laerd.com/spss-tutorials/one-sample-t-test-using-spss-statistics.php)\n",
    "    - No significant outliers\n",
    "    - Normality\n",
    "\n",
    "- [Independent t-test (2-sample)](https://statistics.laerd.com/statistical-guides/independent-t-test-statistical-guide.php)\n",
    "    - No significant outliers\n",
    "    - Normality\n",
    "    - Equal Variance\n",
    "\n",
    "- [One Way ANOVA](https://statistics.laerd.com/spss-tutorials/one-way-anova-using-spss-statistics.php)\n",
    "    - No significant outliers\n",
    "    - Equal variance\n",
    "    - Normality\n",
    "\n",
    "- [Chi-Square test](https://statistics.laerd.com/spss-tutorials/chi-square-test-for-association-using-spss-statistics.php)\n",
    "    - Both variables are categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOW TO: TEST ASSUMPTIONS AND SELECT CORRECT TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Check for & Remove Outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Required for 1-sample t-test and ANOVA.\n",
    "- Use one of the two methods below to identify outliers:\n",
    "    - Use Tukey's interquartile range rule.\n",
    "    - Use absolutely value of Z-scores >3 as rule.\n",
    "- CAUTION: Tukey's IQR method removes more outliers than z-scores. Take care in choosing the appropriate outlier removal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. **Test Assumption of  Normality**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use either of the following tests:\n",
    "    - D'Agostino-Pearson's normality test<br>\n",
    "    ```scipy.stats.normaltest```\n",
    "    - Shapiro-Wilik Test<br>\n",
    "    ```scipy.stats.shapiro```<br>\n",
    "\n",
    "\n",
    "- **1A. If you have normal data:**\n",
    "\n",
    "    - **Move onto assumption \\#2**, testing assumption of equal variance.\n",
    "    \n",
    "    \n",
    "- **1B. If you don't have normal data:** \n",
    "    \n",
    "    > **Check if your group sizes (n) are big enough to safely ignore normality assumption? (see table below)**\n",
    "\n",
    "    - **If your N is big enough:**\n",
    "        - **Move onto assumption \\#2**, testing assumption of equal variance. \n",
    "   - **If you group N's are NOT large enough**:  \n",
    "        - **Move onto step 3.**, selecting the non-parametric version of your t-test\n",
    "     \n",
    "\n",
    "\n",
    "| Parametric Test| Sample size guidelines for nonnormal data| \n",
    "| --- | --- |\n",
    "| 1-sample t test| Greater than 20|\n",
    "| 2-sample t test| Each group should be greater than 15| \n",
    "| One-Way ANOVA|If have 2-9 groups, each group n >= 15. <br>If have 10-12 groups, each group n>20.|\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Test for Equal Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Levene's Test<br>\n",
    "```scipy.stats.levene```\n",
    "\n",
    "- **If you fail the assumption of equal variance:**\n",
    "    - Use a Welch's T-Test.\n",
    "        - for scipy, add `equal_var=False` to `ttest_ind`\n",
    "        \n",
    "        \n",
    "- **If you pass the assumption of equal variance:**\n",
    "    - Use a regular 2-sample t-test.\n",
    "    - See Final Summary Table at the bottom.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Select a non-parametric equivalent of your t-test.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Table Source: Parametric  T-Tests vs Non-Parametric Alternatives**\n",
    "- [Choosing Between Parametric and Non-Parametric Tests](https://blog.minitab.com/blog/adventures-in-statistics-2/choosing-between-a-nonparametric-test-and-a-parametric-test)\n",
    "\n",
    "- **Select the test from the right Nonparametric column that matches your Parametric t-test.** \n",
    "\n",
    "\n",
    "- See final summary table at bottom for scipy functions. \n",
    "\n",
    "| Parametric tests (means) | Nonparametric tests (medians) |\n",
    " | --- | --- |\n",
    " | 1-sample t test | 1-sample Wilcoxon |\n",
    " | 2-sample t test | Mann-Whitney U test |\n",
    " | One-Way ANOVA | Kruskal-Wallis |\n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table - Hypothesis Testing Functions\n",
    "\n",
    "| Parametric tests (means) | Function | Nonparametric tests (medians) | Function |\n",
    " | --- | --- | --- | --- |\n",
    " | **1-sample t test** |`scipy.stats.ttest_1samp()`|  **1-sample Wilcoxon** |`scipy.stats.wilcoxon`|\n",
    " | **2-sample t test** |`scipy.stats.ttest_ind()` | **Mann-Whitney U test** |`scipy.stats.mannwhitneyu()` |\n",
    " | **One-Way ANOVA** | `scipy.stats.f_oneway()` | **Kruskal-Wallis** | `scipy.stats.kruskal` | \n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Interpret Result & Post-Hoc Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Perform hypothesis test from summary table above to get your p-value.**\n",
    "\n",
    "- **If p value is < $\\alpha$:**\n",
    "    - Reject the null hypothesis.\n",
    "    - Calculate effect size (e.g. Cohen's $d$)\n",
    "    \n",
    "- **If p<.05 AND you have multiple groups (i.e. ANOVA)**\n",
    "    - **Must run a pairwise Tukey's test to know which groups were significantly different.**\n",
    "    - [Tukey pairwise comparison test](https://www.statsmodels.org/stable/generated/statsmodels.stats.multicomp.pairwise_tukeyhsd.html)\n",
    "    - `statsmodels.stats.multicomp.pairwise_tukeyhsd`\n",
    "    \n",
    "    \n",
    "- Report statistical power (optional)\n",
    "\n",
    "#### Post-Hoc Functions:\n",
    "\n",
    "| Post-Hoc Tests/Calculatons|Function|\n",
    "|--- | --- |\n",
    "|**Tukey's Pairwise Comparisons** | `statsmodels.stats.multicomp.pairwise_tukeyhsd`|\n",
    "|**Effect Size**| `Cohens_d`|\n",
    "|**Statistical Power** | `statsmodels.stats.power`:<br>  `TTestIndPower` , `TTestPower`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARY TABLES - COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption Tests\n",
    " \n",
    "|Assumption test| Function |\n",
    "| --- | --- |\n",
    "| **Normality**| `scipy.stats.normaltest`|\n",
    "| **Equal Variance** | `scipy.stats.levene`|\n",
    "\n",
    "\n",
    "### Hypothesis Tests\n",
    "\n",
    "| Parametric tests (means) | Function | Nonparametric tests (medians) | Function |\n",
    "| --- | --- | --- | --- |\n",
    "| **1-sample t test** |`scipy.stats.ttest_1samp()`|  **1-sample Wilcoxon** |`scipy.stats.wilcoxon`|\n",
    "| **2-sample t test** |`scipy.stats.ttest_ind()` | **Mann-Whitney U test** |`scipy.stats.mannwhitneyu()`|\n",
    "| **One-Way ANOVA** | `scipy.stats.f_oneway()` | **Kruskal-Wallis** | `scipy.stats.kruskal` | \n",
    "\n",
    " \n",
    " ### Post-Hoc Tests/Calculations\n",
    " \n",
    " | Post-Hoc Tests/Calculatons|Function|\n",
    " |--- | --- |\n",
    " |**Tukey's Pairwise Comparisons** | `statsmodels.stats.multicomp.pairwise_tukeyhsd`|\n",
    " |**Effect Size**| `Cohens_d`|\n",
    " |**Statistical Power** | `statsmodels.stats.power`:<br>  `TTestIndPower` , `TTestPower`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPOTHESIS TESTING STEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate data in group vars.\n",
    "- Visualize data and calculate group n (size)\n",
    "\n",
    "    \n",
    "* Select the appropriate test based on type of comparison being made, the number of groups, the type of data.\n",
    "\n",
    "\n",
    "- For t-tests: test for the assumptions of normality and homogeneity of variance.\n",
    "\n",
    "    1. Check if sample sizes allow us to ignore assumptions, and if not:\n",
    "    2. **Test Assumption Normality**\n",
    "\n",
    "    3. **Test for Homogeneity of Variance**\n",
    "\n",
    "    4. **Choose appropriate test based upon the above** \n",
    "    \n",
    "    \n",
    "* **Perform chosen statistical test, calculate effect size, and any post-hoc tests.**\n",
    "    - To perform post-hoc pairwise comparison testing\n",
    "    - Effect size calculation\n",
    "        - Cohen's d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTIVITY: Sect 22: In-Depth AB Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open in another notebook.\n",
    "    - File path: \"./labs_from_class/sect_22_AB_testing_in_depth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS FOR REFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T22:57:34.986252Z",
     "start_time": "2020-01-28T22:57:28.296707Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "soGUgJ9RRJOp",
    "outputId": "e919e060-8aae-48d4-ed29-3b4637408f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsds_1007219  v0.7.4 loaded.  Read the docs: https://fsds.readthedocs.io/en/latest/ \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_92086fec_4221_11ea_9b7f_acde48001122\" ><caption>Loaded Packages and Handles</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >Handle</th>        <th class=\"col_heading level0 col1\" >Package</th>        <th class=\"col_heading level0 col2\" >Description</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row0_col0\" class=\"data row0 col0\" >dp</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row0_col1\" class=\"data row0 col1\" >IPython.display</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row0_col2\" class=\"data row0 col2\" >Display modules with helpful display and clearing commands.</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row1_col0\" class=\"data row1 col0\" >fs</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row1_col1\" class=\"data row1 col1\" >fsds_100719</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row1_col2\" class=\"data row1 col2\" >Custom data science bootcamp student package</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row2_col0\" class=\"data row2 col0\" >mpl</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row2_col1\" class=\"data row2 col1\" >matplotlib</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row2_col2\" class=\"data row2 col2\" >Matplotlib's base OOP module with formatting artists</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row3_col0\" class=\"data row3 col0\" >plt</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row3_col1\" class=\"data row3 col1\" >matplotlib.pyplot</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row3_col2\" class=\"data row3 col2\" >Matplotlib's matlab-like plotting module</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row4_col0\" class=\"data row4 col0\" >np</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row4_col1\" class=\"data row4 col1\" >numpy</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row4_col2\" class=\"data row4 col2\" >scientific computing with Python</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row5_col0\" class=\"data row5 col0\" >pd</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row5_col1\" class=\"data row5 col1\" >pandas</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row5_col2\" class=\"data row5 col2\" >High performance data structures and tools</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row6_col0\" class=\"data row6 col0\" >sns</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row6_col1\" class=\"data row6 col1\" >seaborn</td>\n",
       "                        <td id=\"T_92086fec_4221_11ea_9b7f_acde48001122row6_col2\" class=\"data row6 col2\" >High-level data visualization library based on matplotlib</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a1cb64400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[i] Pandas .iplot() method activated.']\n"
     ]
    }
   ],
   "source": [
    "!pip install -U fsds_100719\n",
    "from fsds_100719.imports import *\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sms\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T22:58:30.651327Z",
     "start_time": "2020-01-28T22:58:30.648388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Interactive statistical power calculator: https://rpsychologist.com/d3/NHST/\n"
     ]
    }
   ],
   "source": [
    "fs.quick_refs.statistical_power()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions From Doing Sect 22 AB In Depth Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T22:57:24.817385Z",
     "start_time": "2020-01-28T22:57:24.811008Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def Cohen_d(group1, group2, correction = False):\n",
    "    \"\"\"Compute Cohen's d\n",
    "    d = (group1.mean()-group2.mean())/pool_variance.\n",
    "    pooled_variance= (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "\n",
    "    Args:\n",
    "        group1 (Series or NumPy array): group 1 for calculating d\n",
    "        group2 (Series or NumPy array): group 2 for calculating d\n",
    "        correction (bool): Apply equation correction if N<50. Default is False. \n",
    "            - Url with small ncorrection equation: \n",
    "                - https://www.statisticshowto.datasciencecentral.com/cohens-d/ \n",
    "    Returns:\n",
    "        d (float): calculated d value\n",
    "         \n",
    "    INTERPRETATION OF COHEN's D: \n",
    "    > Small effect = 0.2\n",
    "    > Medium Effect = 0.5\n",
    "    > Large Effect = 0.8\n",
    "    \n",
    "    \"\"\"\n",
    "    import scipy.stats as stats\n",
    "    import scipy   \n",
    "    import numpy as np\n",
    "    N = len(group1)+len(group2)\n",
    "    diff = group1.mean() - group2.mean()\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1 = group1.var()\n",
    "    var2 = group2.var()\n",
    "\n",
    "    # Calculate the pooled threshold as shown earlier\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate Cohen's d statistic\n",
    "    d = diff / np.sqrt(pooled_var)\n",
    "    \n",
    "    ## Apply correction if needed\n",
    "    if (N < 50) & (correction==True):\n",
    "        d=d * ((N-3)/(N-2.25))*np.sqrt((N-2)/N)\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "#Your code here\n",
    "def find_outliers_Z(data):\n",
    "    \"\"\"Use scipy to calculate absolute Z-scores \n",
    "    and return boolean series where True indicates it is an outlier.\n",
    "\n",
    "    Args:\n",
    "        data (Series,or ndarray): data to test for outliers.\n",
    "\n",
    "    Returns:\n",
    "        [boolean Series]: A True/False for each row use to slice outliers.\n",
    "        \n",
    "    EXAMPLE USE: \n",
    "    >> idx_outs = find_outliers_df(df['AdjustedCompensation'])\n",
    "    >> good_data = df[~idx_outs].copy()\n",
    "    \"\"\"\n",
    "    import scipy.stats as stats\n",
    "    ## Calculate z-scores\n",
    "    zs = stats.zscore(data)\n",
    "    \n",
    "    ## Find z-scores >3 awayfrom mean\n",
    "    idx_outs = np.abs(zs)>3\n",
    "    \n",
    "    ## If input was a series, make idx_outs index match\n",
    "    if isinstance(data,pd.Series):\n",
    "        return pd.Series(idx_outs,index=data.index)\n",
    "    else:\n",
    "        return pd.Series(idx_outs)\n",
    "    \n",
    "    \n",
    "    \n",
    "def find_outliers_IQR(data):\n",
    "    \"\"\"Use Tukey's Method of outlier removal AKA InterQuartile-Range Rule\n",
    "    and return boolean series where True indicates it is an outlier.\n",
    "    - Calculates the range between the 75% and 25% quartiles\n",
    "    - Outliers fall outside upper and lower limits, using a treshold of  1.5*IQR the 75% and 25% quartiles.\n",
    "\n",
    "    IQR Range Calculation:    \n",
    "        res = df.describe()\n",
    "        IQR = res['75%'] -  res['25%']\n",
    "        lower_limit = res['25%'] - 1.5*IQR\n",
    "        upper_limit = res['75%'] + 1.5*IQR\n",
    "\n",
    "    Args:\n",
    "        data (Series,or ndarray): data to test for outliers.\n",
    "\n",
    "    Returns:\n",
    "        [boolean Series]: A True/False for each row use to slice outliers.\n",
    "        \n",
    "    EXAMPLE USE: \n",
    "    >> idx_outs = find_outliers_df(df['AdjustedCompensation'])\n",
    "    >> good_data = df[~idx_outs].copy()\n",
    "    \n",
    "    \"\"\"\n",
    "    df_b=data\n",
    "    res= df_b.describe()\n",
    "\n",
    "    IQR = res['75%'] -  res['25%']\n",
    "    lower_limit = res['25%'] - 1.5*IQR\n",
    "    upper_limit = res['75%'] + 1.5*IQR\n",
    "\n",
    "    idx_outs = (df_b>upper_limit) | (df_b<lower_limit)\n",
    "\n",
    "    return idx_outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Group Data and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_IQR(data,col=None):\n",
    "    \"\"\"\n",
    "    Use Tukey's Method of outlier removal AKA InterQuartile-Range Rule\n",
    "    and return boolean series where True indicates it is an outlier.\n",
    "    - Calculates the range between the 75% and 25% quartiles\n",
    "    - Outliers fall outside upper and lower limits, using a treshold of  1.5*IQR the 75% and 25% quartiles.\n",
    "\n",
    "    IQR Range Calculation:    \n",
    "        res = df.describe()\n",
    "        IQR = res['75%'] -  res['25%']\n",
    "        lower_limit = res['25%'] - 1.5*IQR\n",
    "        upper_limit = res['75%'] + 1.5*IQR\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame,Series,or ndarray): data to test for outliers.\n",
    "        col (str): If passing a DataFrame, must specify column to use.\n",
    "\n",
    "    Returns:\n",
    "        [boolean Series]: A True/False for each row use to slice outliers.\n",
    "        \n",
    "    EXAMPLE USE: \n",
    "    >> idx_outs = find_outliers_df(df,col='AdjustedCompensation')\n",
    "    >> good_data = data[~idx_outs].copy()\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        if col is None:\n",
    "            raise Exception('If passing a DataFrame, must provide col=')\n",
    "        else:\n",
    "            data = data[col]\n",
    "    elif isinstance(data,np.ndarray):\n",
    "        data= pd.Series(data)\n",
    "\n",
    "    elif isinstance(data,pd.Series):\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('data must be a DataFrame, Series, or np.ndarray')\n",
    "    \n",
    "    res = data.describe()\n",
    "        \n",
    "    \n",
    "    IQR = res['75%'] -  res['25%']\n",
    "    lower_limit = res['25%'] - 1.5*IQR\n",
    "    upper_limit = res['75%'] + 1.5*IQR\n",
    "\n",
    "    idx_outs = (data>upper_limit) | (data<lower_limit) \n",
    "\n",
    "    return idx_outs\n",
    "\n",
    "\n",
    "\n",
    "def find_outliers_Z(data,col=None):\n",
    "    \"\"\"Use scipy to calcualte absoliute Z-scores \n",
    "    and return boolean series where True indicates it is an outlier\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame,Series,or ndarray): data to test for outliers.\n",
    "        col (str): If passing a DataFrame, must specify column to use.\n",
    "\n",
    "    Returns:\n",
    "        [boolean Series]: A True/False for each row use to slice outliers.\n",
    "        \n",
    "    EXAMPLE USE: \n",
    "    >> idx_outs = find_outliers_df(df,col='AdjustedCompensation')\n",
    "    >> good_data = data[~idx_outs].copy()\n",
    "    \"\"\"\n",
    "    \n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        if col is None:\n",
    "            raise Exception('If passing a DataFrame, must provide col=')\n",
    "        else:\n",
    "            data = data[col]\n",
    "    elif isinstance(data,np.ndarray):\n",
    "        data= pd.Series(data)\n",
    "\n",
    "    elif isinstance(data,pd.Series):\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('data must be a DataFrame, Series, or np.ndarray')\n",
    "    \n",
    "    z = np.abs(stats.zscore(data))\n",
    "    idx_outliers = np.where(z>3,True,False)\n",
    "    return idx_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T20:57:36.987742Z",
     "start_time": "2020-01-26T20:57:36.980162Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_dists(grp1,grp2,col='BL',name1='Exp',name2='Control'):\n",
    "\n",
    "    ## Defining \"gridspec_kws\" for plt.subplots()\n",
    "    ## This will make our first plot 3 times wider than the second.\n",
    "    gs_kw = dict(width_ratios=[3, 1])\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(10,4),ncols=2,\n",
    "                             gridspec_kw=gs_kw,constrained_layout=True)\n",
    "\n",
    "    ## Defining the data \n",
    "    group1 = {'name':name1, \n",
    "             'data':grp1[col],\n",
    "             'plot_specs':{\n",
    "                 'hist_kws':dict(color='b', lw=2,ls='-'),\n",
    "                 'kde_kws':dict(color='b',lw=1,ls='-'),\n",
    "                 'label':f\"{name1} (n={len(grp1[col])})\"}\n",
    "             }\n",
    "    \n",
    "    group2 = {'name':name2, \n",
    "             'data':grp2[col],\n",
    "              'plot_specs':{\n",
    "                  'hist_kws':dict(color='orange', lw=2,ls='-'),\n",
    "                  'kde_kws':dict(color='orange',lw=1,ls='-'),\n",
    "                   'label':f\"{name2} (n={len(grp2[col])})\"}\n",
    "             }\n",
    "    \n",
    "    \n",
    "    ax=axes[0]\n",
    "    sns.distplot(group1['data'], **group1['plot_specs'],ax=axes[0])\n",
    "    sns.distplot(group2['data'], **group2['plot_specs'],ax=axes[0])\n",
    "    ax.legend()\n",
    "    \n",
    "    ax.set(ylabel=\"Density\")\n",
    "    ax.set(xlabel='Number of Licks')\n",
    "    \n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.bar(group1['name'],group1['data'].mean(),\n",
    "          yerr=sem(group1['data']))\n",
    "\n",
    "    ax.bar(group2['name'],group2['data'].mean(),\n",
    "          yerr=sem(group2['data']))    \n",
    "    \n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T22:50:31.197808Z",
     "start_time": "2020-01-23T22:50:31.195479Z"
    }
   },
   "source": [
    "### Writing functions to test assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T20:57:36.993416Z",
     "start_time": "2020-01-26T20:57:36.989060Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def test_normality(grp_control,col='BL',alpha=0.05):\n",
    "    import scipy.stats as stats\n",
    "    stat,p =stats.normaltest(grp_control[col])\n",
    "    if p<alpha:\n",
    "        print(f\"Normal test p value of {np.round(p,3)} is < {alpha}, therefore data is NOT normal.\")\n",
    "    else:\n",
    "        print(f\"Normal test p value of {np.round(p,3)} is > {alpha}, therefore data IS normal.\")\n",
    "    return p\n",
    "\n",
    "def test_equal_variance(grp1,grp2, alpha=.05):\n",
    "    stat,p = stats.levene(grp1,grp2)\n",
    "    if p<alpha:\n",
    "        print(f\"Levene's test p value of {np.round(p,3)} is < {alpha}, therefore groups do NOT have equal variance.\")\n",
    "    else:\n",
    "        print(f\"Normal test p value of {np.round(p,3)} is > {alpha},  therefore groups DOES have equal variance.\")\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions from Last Class to Make Bite-Sized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T20:57:37.003760Z",
     "start_time": "2020-01-26T20:57:36.994638Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_statplot(df_means,grps=None,\n",
    "                  group_col='Group',data_col='BL'):\n",
    "    \n",
    "    if grps is None:\n",
    "        grps = df_means.groupby(group_col).groups\n",
    "\n",
    "    ## Examine KDEs for BL\n",
    "    fig= plt.figure(figsize=(10,6))\n",
    "    axes=['','']\n",
    "    # Define gridspec to create grid coordinates             \n",
    "    gs = fig.add_gridspec(nrows=1,ncols=9)\n",
    "    axes[0] = fig.add_subplot(gs[0,0:7])\n",
    "    axes[1] = fig.add_subplot(gs[0,7:])\n",
    "\n",
    "    data1=df_means.loc[grps['ChR2'],data_col]\n",
    "    data2=df_means.loc[grps['Control'],data_col]\n",
    "    \n",
    "    group1 = {'name':'ChR2',\n",
    "             'data':data1,#df_means.loc[grps['ChR2'],data_col],\n",
    "             'n':len(data1)}\n",
    "    plot1 = {'hist_kws':dict(color='blue',lw=2, ls='-')}#,bins='auto')}\n",
    "\n",
    "    group2 = {'name':'Control',\n",
    "             'data':data2,#df_means.loc[grps['Control'],data_col],\n",
    "             'n':len(data2)}\n",
    "    plot2 = {'hist_kws':dict(color='orange',lw=2, ls='-')}#,bins='auto')}\n",
    "    \n",
    "    ax = axes[0]\n",
    "    label1= f\"{group1['name']} n={group1['n']}\"\n",
    "    sns.distplot(group1['data'], label=label1,\n",
    "                 ax=ax, hist_kws=plot1['hist_kws'])\n",
    "    # ax.legend()\n",
    "\n",
    "    label2= f\"{group2['name']} n={group2['n']}\"\n",
    "    sns.distplot(group2['data'], label=label2,\n",
    "                 ax=ax,hist_kws=plot2['hist_kws'])\n",
    "    ax.legend()\n",
    "\n",
    "    \n",
    "\n",
    "    ax.axvline(group1['data'].mean(),color=plot1['hist_kws']['color'], ls='--')\n",
    "    ax.axvline(group2['data'].mean(),color=plot2['hist_kws']['color'], ls='--')\n",
    "\n",
    "\n",
    "    ax = axes[1]\n",
    "\n",
    "    ax.bar(group1['name'],group1['data'].mean(),\n",
    "          yerr=sem(group1['data']))\n",
    "\n",
    "    ax.bar(group2['name'],group2['data'].mean(),\n",
    "          yerr=sem(group2['data']))\n",
    "    \n",
    "    plt.suptitle(f\"Phase = {data_col}\",fontsize=20)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T20:57:44.363709Z",
     "start_time": "2020-01-26T20:57:44.354237Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_assumptions(df_means,grps=None,\n",
    "                     group_col='Group',\n",
    "                     grp1='ChR2',\n",
    "                     grp2='Control',\n",
    "                     data_col='BL',\n",
    "                    plot_data=False):\n",
    "    \"\"\"MASSIVE FUNCTION PASTED IN DUE TO VERY LATE STUDY GROUP\n",
    "    WE WILL CONSTRUCT A BETTER/SIMPLER VERSION OF THIS TOGETHER IN NEXT STUDY GROUP.\"\"\"\n",
    "    \n",
    "    if grps is None:\n",
    "        grps = df_means.groupby(group_col).groups\n",
    "        \n",
    "        \n",
    "    group1 = {'name':grp1,\n",
    "              'data':df_means.loc[grps[grp1],data_col]}\n",
    "    \n",
    "    group2 = {'name':grp2,\n",
    "              'data':df_means.loc[grps[grp2],data_col]}\n",
    "    \n",
    "    results = [['Col','Test','Group(s)','Stat','p','p<.05']]\n",
    "    \n",
    "    ## Normality testing\n",
    "    stat,p = stats.normaltest(group1['data'])\n",
    "    results.append([data_col,'Normality',group1['name'],\n",
    "                  stat, p, p<.05])\n",
    "    \n",
    "    stat,p = stats.normaltest(group2['data'])    \n",
    "    results.append([data_col,'Normality',group2['name'],\n",
    "                  stat, p, p<.05])\n",
    "    ## Homo. of Variance Testing\n",
    "    stat,p = stats.levene(group1['data'],group2['data'])\n",
    "    results.append([data_col,'Equal Variance','Both',\n",
    "                  stat, p, p<.05])\n",
    "    \n",
    "    \n",
    "    ## Parametric T-Test\n",
    "    stat,p = stats.ttest_ind(group1['data'],group2['data'])\n",
    "    results.append([data_col,'T-Test 2samp','Both',stat,p,p<.05])\n",
    "    \n",
    "    ## Non-Parametric MWU\n",
    "    stat,p = stats.mannwhitneyu(group1['data'],group2['data'])\n",
    "    results.append([data_col,'Mann Whitney U','Both',stat,p,p<.05])\n",
    "    \n",
    "    ## Effect size with Cohen's d\n",
    "    d = Cohen_d(group1['data'],group2['data'])\n",
    "    results.append([data_col, \"Cohen's d\", 'Both','','',d])\n",
    "    \n",
    "#     if plot_data:\n",
    "#         plot_dists(grp, col=data_col)\n",
    "    \n",
    "    return pd.DataFrame(results[1:],columns=results[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sect 18+19  with Titanic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290.909px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "360.85px",
    "left": "630px",
    "right": "20px",
    "top": "38px",
    "width": "480px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
