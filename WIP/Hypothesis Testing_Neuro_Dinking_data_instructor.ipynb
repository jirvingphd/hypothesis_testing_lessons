{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZM6DyjYckZl2"
   },
   "source": [
    "\n",
    "# Hypothesis Testing with Neuro Data - RM ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This notebook is intended to walk through preparing my binge drinking data for Hypothesis Testing\n",
    "- Specifically, in this notebook I will attempt to use the most appropriate stat tests, which are not taught in the Learn curriculum\n",
    "\n",
    "\n",
    "- **Repeated Measures ANOVA in Python**\n",
    "-  **Two way RM ANOVA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [RM ANOVA IN Python with Statsmodels](https://www.marsja.se/repeated-measures-anova-in-python-using-statsmodels/)\n",
    "- One-way RM ANOVA (other packages): https://www.marsja.se/repeated-measures-anova-using-python/\n",
    "- Two-Way: https://marsja.se/two-way-anova-repeated-measures-using-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests Summary Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Parametric tests (means) | Function | Nonparametric tests (medians) | Function |\n",
    " | --- | --- | --- | --- |\n",
    " | 1-sample t test |`scipy.stats.ttest_1samp()`|  1-sample Wilcoxon |`scipy.stats.wilcoxon`|\n",
    " | 2-sample t test |`scipy.stats.ttest_ind()` | Mann-Whitney U test |`scipy.stats.mannwhitneyu()` |\n",
    " | One-Way ANOVA | `scipy.stats.f_oneway()` | Kruskal-Wallis | `scipy.stats.kruskal` | \n",
    " \n",
    " \n",
    " | Factorial DOE with one factor and one blocking variable |Friedman test  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T22:34:50.811862Z",
     "start_time": "2020-01-21T22:34:50.809738Z"
    }
   },
   "source": [
    "# Real-World Science / Experimental Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [James' Neuroscience Research Poster: Society for Neuroscience 2016](https://drive.google.com/open?id=14z2dUdPB_8ei3HA7R1j3ylwEP0kVZhJq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Role of Stress Neurons in the Amygdala in Addiction/Binge Drinking\n",
    "\n",
    "- We will be talking through some of the experiments from my Postdoctoral research on the roll of stress neurons in the escalation of binge drinking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Opponent-Process Theory of Addiction \n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_pt_100719_cohort_notes/master/Images/robinson-berridge-fig1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on prior evidence in the field, stress neurons in the amygdala are believed to be responsible for the negative emotions that promote binge consumption to relieve negative symptoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ H_1$: Increasing the activity of stress neurons (CRF neurons) in the amygdala will increase the amount of alcohol consumed by binge-drinking mice.\n",
    "\n",
    "$H_0$: Stimulation of CRF neurons has no effect on the amount of alcohol consumed.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_pt_100719_cohort_notes/master/Images/jmi_poster_preds1.png\" width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_pt_100719_cohort_notes/master/Images/opto_6steps.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/hypothesis_testing_lessons/master/images/jmi_poster_fig1_no_mouse.png\">\n",
    "\n",
    "<!---\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/hypothesis_testing_lessons/master/images/jmi_poster_fig1.png\">--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T22:44:58.893416Z",
     "start_time": "2020-01-21T22:44:58.889888Z"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_pt_100719_cohort_notes/master/Images/jmi_poster_fig2.png\">\n",
    "\n",
    "<!---\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/images/sect_20_neuro_data.png\">')\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing: Mouse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "> Question: does stimulation of CRF Neurons in the central amygdala increase alcohol consumption?\n",
    "\n",
    "- Metric: licks for alcohol\n",
    "- Two groups: Control and Experimental (ChR2)\n",
    "\n",
    "\n",
    "- $H_1$: There is a significant difference in average licks for alcohol between control and experimental/stimulated mice.\n",
    "\n",
    "- $H_0$: There is no significant difference in licks for alcohol between control and experimental/stimulated mice.\n",
    "\n",
    "$\\alpha$=0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: which type of test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What type of data?\n",
    "    - Numerical\n",
    "- How many groups?\n",
    "    - 2 groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:48:35.254889Z",
     "start_time": "2020-07-01T19:48:35.253000Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# HTML('<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/images/sect_20_neuro_data.png\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.614112Z",
     "start_time": "2020-07-01T19:42:03.297071Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "soGUgJ9RRJOp",
    "outputId": "e919e060-8aae-48d4-ed29-3b4637408f13"
   },
   "outputs": [],
   "source": [
    "!pip install -U fsds\n",
    "from fsds.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.621206Z",
     "start_time": "2020-07-01T19:42:06.616745Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-poster')\n",
    "pd.set_option('display.max_columns',0)\n",
    "pd.set_option('display.precision',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining/Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.677088Z",
     "start_time": "2020-07-01T19:42:06.623393Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Neuroscience/mouse_drinking_data_cleaned.csv\",index_col=0)\n",
    "df.drop('Sex',inplace=True,axis=1)\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laying Out Our Approach\n",
    "\n",
    "1. Make a **dict/lists of the column names** that should be **averaged together** (`col_dict`)\n",
    "\n",
    "2. Make a new df of means using `col_dict`\n",
    "\n",
    "3. Make a grp dict using  `df_means.groupby('Group').groups` \n",
    "\n",
    "- Visualize the two populations\n",
    "\n",
    "- Prepare for hypothesis tests\n",
    "    - Either use `grps` dict to reference the correct columsn to pass into tests\n",
    "\n",
    "<!---\n",
    "**Variables:**\n",
    "\n",
    "- `col_dict` (dict): dict of column names to be grouped together for means\n",
    "- `df_means` (df): df of col_dict column means.\n",
    "- `grps` (dict): groupby dict where keys = 'Group' column and values = row indices\n",
    "\n",
    "- `data` (dict): Dictionary of...\n",
    "    - Series of each phase by group? --->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.683773Z",
     "start_time": "2020-07-01T19:42:06.678572Z"
    }
   },
   "outputs": [],
   "source": [
    "phases = ['BL','S','PS','R1','R2']\n",
    "col_dict = {}\n",
    "for phase in phases:\n",
    "    col_dict[phase] = [col for col in df.columns if col.startswith(phase) ]\n",
    "col_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.687483Z",
     "start_time": "2020-07-01T19:42:06.685282Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Make lists of columns to be averaged together\n",
    "# BL_cols = [col for col in df.columns if 'BL' in col]\n",
    "# PS_cols = [col for col in df.columns if 'PS' in col]\n",
    "# R1_cols = [col for col in df.columns if 'R1_' in col]\n",
    "# R2_cols = [col for col in df.columns if 'R2_' in col]\n",
    "# S_cols= [col for col in df.drop(PS_cols,axis=1) if 'S' in col]\n",
    "\n",
    "# col_dict = {'BL':BL_cols,\n",
    "#            'S':S_cols,\n",
    "#            'PS':PS_cols,\n",
    "#            'R1':R1_cols,\n",
    "#             'R2':R2_cols}\n",
    "\n",
    "\n",
    "# col_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.690997Z",
     "start_time": "2020-07-01T19:42:06.688828Z"
    }
   },
   "outputs": [],
   "source": [
    "# phase_dict = {col:phase for phase,col}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.696288Z",
     "start_time": "2020-07-01T19:42:06.692393Z"
    }
   },
   "outputs": [],
   "source": [
    "list(map(lambda x: col_dict[x],col_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.702101Z",
     "start_time": "2020-07-01T19:42:06.698212Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phase_dict = {}\n",
    "for phase,colnames in col_dict.items():\n",
    "    for col in colnames:\n",
    "        phase_dict[col] = phase\n",
    "\n",
    "\n",
    "phase_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.739820Z",
     "start_time": "2020-07-01T19:42:06.703476Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melting DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.764631Z",
     "start_time": "2020-07-01T19:42:06.741027Z"
    }
   },
   "outputs": [],
   "source": [
    "## MELTING THE DATA INTO FORM WORKABLE FOR PLOTS/ANALYSIS\n",
    "df2= pd.melt(df.reset_index(),id_vars=['Mouse_ID','Group'],\n",
    "              value_name='Licks',var_name='Day')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:06.794278Z",
     "start_time": "2020-07-01T19:42:06.766145Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Mapping Phase from Phase Dict\n",
    "df2['Phase'] = df2['Day'].map(phase_dict)\n",
    "\n",
    "## Getting Day of Phase\n",
    "df2['Day_of_Phase'] = df2['Day'].apply(lambda x: x[-1])\n",
    "# df2 = df2.dropna(subset=['Phase'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:42:39.016848Z",
     "start_time": "2020-07-01T19:42:39.009090Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2.to_csv('../Neuroscience/mouse_drinking_data_melted.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:43:02.119604Z",
     "start_time": "2020-07-01T19:43:02.117616Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.read_csv('../Neuroscience/mouse_drinking_data_melted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📕 TO DO (06/30/20): RM_ANOVA\n",
    "\n",
    "> ## Main Resources\n",
    "- https://www.marsja.se/repeated-measures-anova-in-python-using-statsmodels/\n",
    "\n",
    "> ### Additional Resources\n",
    "- https://www.marsja.se/three-ways-to-carry-out-2-way-anova-with-python/\n",
    "- https://www.marsja.se/four-ways-to-conduct-one-way-anovas-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:43:25.339645Z",
     "start_time": "2020-07-01T19:43:25.313307Z"
    }
   },
   "outputs": [],
   "source": [
    "df_melt = pd.read_csv('../Neuroscience/mouse_drinking_data_melted.csv')\n",
    "df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:43:49.650209Z",
     "start_time": "2020-07-01T19:43:49.640399Z"
    }
   },
   "outputs": [],
   "source": [
    "del df2\n",
    "# del df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T19:44:01.842324Z",
     "start_time": "2020-07-01T19:44:01.780437Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df.pivot_table(values='Licks',index=['Group','Mouse_ID'],\n",
    "                      columns=['Phase','Day_of_Phase'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:31:14.422441Z",
     "start_time": "2020-07-01T01:31:14.419760Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.groupby(['Group','Mouse_ID'])['Mouse_ID'].count()#.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES (06/29/30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 52 observations for ChR2, but only 36 for Control.\n",
    "    - This is probably why RMANOVA returns an error\n",
    "    \n",
    "- Possible Solutions:\n",
    "    - Remove mice from ChR2 group to match Control\n",
    "    - Resample from Control Group to match ChR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:31:14.433616Z",
     "start_time": "2020-07-01T01:31:14.424636Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "for grp in df.groupby('Group').groups:\n",
    "    data[grp] = df.groupby('Group').get_group(grp)\n",
    "    print(grp)\n",
    "    print(len(data[grp]['Mouse_ID'].unique()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:31:26.677723Z",
     "start_time": "2020-07-01T01:31:26.675437Z"
    }
   },
   "outputs": [],
   "source": [
    "n_to_match = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying which Mice to Remove (outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:31:28.132228Z",
     "start_time": "2020-07-01T01:31:28.130135Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ## Making df that can be used with plotly express\n",
    "# plotly_df = df2.copy()\n",
    "# # plotly_df['Day_of_Phase'] = plotly_df['Day'].apply(lambda x: x[-1])\n",
    "# plotly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:31:29.197230Z",
     "start_time": "2020-07-01T01:31:28.516667Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.box(df,x='Phase',y='Licks',\n",
    "       color='Group',hover_name='Mouse_ID',height=400)#,\n",
    "#       category_orders=['BL','S','PS','R1','R2'])#,points='suspectedoutliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Mice to Remove (try normalized first):\n",
    "    - ChR2:\n",
    "        - 20\n",
    "    - Control:\n",
    "        - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOPPING POINT [06/30/20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:32:31.479955Z",
     "start_time": "2020-07-01T01:32:31.452797Z"
    }
   },
   "outputs": [],
   "source": [
    "df_anova_phases = df.pivot_table(index=['Group','Mouse_ID'],values='Licks',columns=['Phase'])\n",
    "display(df_anova_phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:33:16.900546Z",
     "start_time": "2020-07-01T01:33:16.876074Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalizing N's|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:31:31.040187Z",
     "start_time": "2020-07-01T01:31:31.036134Z"
    }
   },
   "outputs": [],
   "source": [
    "n_chr2 = len(df_anova_phases.loc['ChR2'])\n",
    "n_control= len(df_anova_phases.loc['Control'])\n",
    "n_to_match = max( n_chr2,n_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:33:42.051883Z",
     "start_time": "2020-07-01T01:33:42.027887Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:38:23.867443Z",
     "start_time": "2020-07-01T01:38:23.838099Z"
    }
   },
   "outputs": [],
   "source": [
    "## Resample dfa\n",
    "\n",
    "\n",
    "df_list = []\n",
    "# df_anova_phases.reset_index(inplace=True)\n",
    "for group in df[\"Group\"].unique():\n",
    "    grp_df = df.groupby('Group').get_group(group)\n",
    "    grp_df = grp_df.sample(n=n_to_match,replace=True,random_state=123)\n",
    "    df_list.append(grp_df)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:38:25.478712Z",
     "start_time": "2020-07-01T01:38:25.455250Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import AnovaRM\n",
    "df_resamp = pd.concat(df_list)\n",
    "df_resamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:38:26.517203Z",
     "start_time": "2020-07-01T01:38:26.267218Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.box(df_resamp,x='Phase',y='Licks',\n",
    "       color='Group',hover_name='Mouse_ID',height=400)#,\n",
    "#       category_orders=['BL','S','PS','R1','R2'])#,points='suspectedoutliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:38:26.667352Z",
     "start_time": "2020-07-01T01:38:26.665391Z"
    }
   },
   "outputs": [],
   "source": [
    "# n_to_match = df2_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:38:27.211436Z",
     "start_time": "2020-07-01T01:38:27.209537Z"
    }
   },
   "outputs": [],
   "source": [
    "# grp_dict = df_anova_phases.groupby('Group').groups\n",
    "\n",
    "# ## Match the largest number of subjects\n",
    "# n_to_match = max(list(map(lambda x: len(x),grp_dict.values())))\n",
    "# n_to_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:38:27.413867Z",
     "start_time": "2020-07-01T01:38:27.411947Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_list = []\n",
    "# for group in df_anova_phases[\"Group\"].unique():\n",
    "#     grp_df = df_anova_phases.groupby('Group').get_group(group)\n",
    "#     grp_df = grp_df.sample(n=n_to_match,replace=True)\n",
    "#     df_list.append(grp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:38:27.616783Z",
     "start_time": "2020-07-01T01:38:27.614755Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_anova_equal = pd.concat(df_list)\n",
    "# df_anova_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RM ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:38:50.060669Z",
     "start_time": "2020-07-01T01:38:50.036149Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:38:47.201906Z",
     "start_time": "2020-07-01T01:38:47.199877Z"
    }
   },
   "outputs": [],
   "source": [
    "# # df2.pivot_table(index=['Group','Mouse_ID'],columns=['Day'])\n",
    "# df_resamp.reset_index(drop=True,inplace=True)#.pivot_table(index=['Group','Day_of_Phase','Mouse_ID'])#,columns=['Day'])\n",
    "# df_resamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:38:52.886524Z",
     "start_time": "2020-07-01T01:38:52.884348Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_resamp['Phase'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:41:12.688187Z",
     "start_time": "2020-07-01T01:41:12.667498Z"
    }
   },
   "outputs": [],
   "source": [
    "aovrm = AnovaRM(df, 'Licks', 'Mouse_ID', within=['Phase','Group'],aggregate_func=np.nanmean).fit()\n",
    "aovrm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.110064Z",
     "start_time": "2020-07-01T00:53:16.357Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.110847Z",
     "start_time": "2020-07-01T00:53:16.361Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "statsmodels.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.111569Z",
     "start_time": "2020-07-01T00:53:16.363Z"
    }
   },
   "outputs": [],
   "source": [
    "anovarm = AnovaRM(df2,'Licks','Mouse_ID',within=['Day'],\n",
    "                 aggregate_func='mean')#between=['Group'],\n",
    "res = anovarm.fit()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.112361Z",
     "start_time": "2020-07-01T00:53:16.369Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_to_df = {}\n",
    "for k, cols in col_dict.items():\n",
    "    mean_to_df[k] = df[cols].mean(axis=1)\n",
    "    \n",
    "df_means = pd.concat([df[['Mouse ID','Group','Sex']],\n",
    "                      pd.DataFrame(mean_to_df)],axis=1)\n",
    "df_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.113236Z",
     "start_time": "2020-07-01T00:53:16.371Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_means.to_csv('../datasets/neuro_mouse_dirnking.csv',index=False)\n",
    "# df_means = pd.read_csv('../datasets/neuro_mouse_dirnking.csv')\n",
    "# df_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Group Data For EDA & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.114266Z",
     "start_time": "2020-07-01T00:53:16.374Z"
    }
   },
   "outputs": [],
   "source": [
    "df_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.115188Z",
     "start_time": "2020-07-01T00:53:16.376Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get grps \n",
    "\n",
    "## Two different ways of using groupby\n",
    "grps = df_means.groupby('Group').groups\n",
    "\n",
    "grp_control = df_means.loc[grps['Control']]\n",
    "grp_exp = df_means.groupby('Group').get_group('ChR2')\n",
    "#grpB\n",
    "# grps\n",
    "display( grp_exp.head().style.set_caption('Exp/ChR2'),\n",
    "        grp_control.head().style.set_caption('Controls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.116135Z",
     "start_time": "2020-07-01T00:53:16.379Z"
    }
   },
   "outputs": [],
   "source": [
    "## Group counts\n",
    "len(grp_control), len(grp_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.116898Z",
     "start_time": "2020-07-01T00:53:16.381Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# sns.distplot(grp_control['BL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.117593Z",
     "start_time": "2020-07-01T00:53:16.384Z"
    }
   },
   "outputs": [],
   "source": [
    "# sem(grp_exp['BL'])\n",
    "# sem(grp_control['BL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.118304Z",
     "start_time": "2020-07-01T00:53:16.387Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "## showing off SEM bars\n",
    "f,ax = plt.subplots(figsize=(5,5))\n",
    "ax.bar('Exp',grp_exp['BL'],yerr=sem(grp_exp['BL']))\n",
    "ax.bar('Control',grp_control['BL'],yerr=sem(grp_control['BL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.119048Z",
     "start_time": "2020-07-01T00:53:16.389Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_dists(grp1,grp2,col='BL',name1='Exp',name2='Control'):\n",
    "\n",
    "    ## Defining \"gridspec_kws\" for plt.subplots()\n",
    "    ## This will make our first plot 3 times wider than the second.\n",
    "    gs_kw = dict(width_ratios=[3, 1])\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(10,4),ncols=2,\n",
    "                             gridspec_kw=gs_kw,constrained_layout=True)\n",
    "\n",
    "    ## Defining the data \n",
    "    group1 = {'name':name1, \n",
    "             'data':grp1[col],\n",
    "             'plot_specs':{\n",
    "                 'hist_kws':dict(color='b', lw=2,ls='-'),\n",
    "                 'kde_kws':dict(color='b',lw=1,ls='-'),\n",
    "                 'label':f\"{name1} (n={len(grp1[col])})\"}\n",
    "             }\n",
    "    \n",
    "    group2 = {'name':name2, \n",
    "             'data':grp2[col],\n",
    "              'plot_specs':{\n",
    "                  'hist_kws':dict(color='orange', lw=2,ls='-'),\n",
    "                  'kde_kws':dict(color='orange',lw=1,ls='-'),\n",
    "                   'label':f\"{name2} (n={len(grp2[col])})\"}\n",
    "             }\n",
    "    \n",
    "    \n",
    "    ax=axes[0]\n",
    "    sns.distplot(group1['data'], **group1['plot_specs'],ax=axes[0])\n",
    "    sns.distplot(group2['data'], **group2['plot_specs'],ax=axes[0])\n",
    "    ax.legend()\n",
    "    \n",
    "    ax.set(ylabel=\"Density\")\n",
    "    ax.set(xlabel='Number of Licks')\n",
    "    \n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.bar(group1['name'],group1['data'].mean(),\n",
    "          yerr=sem(group1['data']))\n",
    "\n",
    "    ax.bar(group2['name'],group2['data'].mean(),\n",
    "          yerr=sem(group2['data']))    \n",
    "    \n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.119937Z",
     "start_time": "2020-07-01T00:53:16.391Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plot_dists(grp_control,grp_exp,col='R',name1='ChR2', name2='Control')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T22:50:31.197808Z",
     "start_time": "2020-01-23T22:50:31.195479Z"
    }
   },
   "source": [
    "### Writing functions to test assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.120730Z",
     "start_time": "2020-07-01T00:53:16.394Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "stats.normaltest(grp_control['BL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.121456Z",
     "start_time": "2020-07-01T00:53:16.396Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def test_normality(grp_control,col='BL',alpha=0.05):\n",
    "    import scipy.stats as stats\n",
    "    stat,p =stats.normaltest(grp_control[col])\n",
    "    if p<alpha:\n",
    "        print(f\"Normal test p value of {np.round(p,3)} is < {alpha}, therefore data is NOT normal.\")\n",
    "    else:\n",
    "        print(f\"Normal test p value of {np.round(p,3)} is > {alpha}, therefore data IS normal.\")\n",
    "    return p\n",
    "\n",
    "def test_equal_variance(grp1,grp2, alpha=.05):\n",
    "    stat,p = stats.levene(grp1,grp2)\n",
    "    if p<alpha:\n",
    "        print(f\"Levene's test p value of {np.round(p,3)} is < {alpha}, therefore groups do NOT have equal variance.\")\n",
    "    else:\n",
    "        print(f\"Normal test p value of {np.round(p,3)} is > {alpha},  therefore groups DOES have equal variance.\")\n",
    "    return p\n",
    "\n",
    "\n",
    "\n",
    "# def test_assumptions(*args, normal=True,equal_var=True):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.122251Z",
     "start_time": "2020-07-01T00:53:16.399Z"
    }
   },
   "outputs": [],
   "source": [
    "test_normality(grp_control,col='S'), test_normality(grp_exp,col='S');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.123069Z",
     "start_time": "2020-07-01T00:53:16.401Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def Cohen_d(group1, group2):\n",
    "    \"\"\"\n",
    "    Compute Cohen's d.\n",
    "    \n",
    "    Args:\n",
    "        group1: Series or NumPy array\n",
    "        group2: Series or NumPy array\n",
    "\n",
    "    Returns:\n",
    "        d (float): effect size statistic\n",
    "\n",
    "    Interpretation:\n",
    "    > Small effect = 0.2\n",
    "    > Medium Effect = 0.5\n",
    "    > Large Effect = 0.8\n",
    "    \"\"\"\n",
    "    diff = group1.mean() - group2.mean()\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1 = group1.var()\n",
    "    var2 = group2.var()\n",
    "\n",
    "    # Calculate the pooled threshold as shown earlier\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate Cohen's d statistic\n",
    "    d = diff / np.sqrt(pooled_var)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: Functions below pasted in due to time. Will construct smaller but similar functions together next class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.123878Z",
     "start_time": "2020-07-01T00:53:16.404Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_statplot(df_means,grps=None,\n",
    "                  group_col='Group',data_col='BL'):\n",
    "    \n",
    "    if grps is None:\n",
    "        grps = df_means.groupby(group_col).groups\n",
    "\n",
    "    ## Examine KDEs for BL\n",
    "    fig= plt.figure(figsize=(10,6))\n",
    "    axes=['','']\n",
    "    # Define gridspec to create grid coordinates             \n",
    "    gs = fig.add_gridspec(nrows=1,ncols=9)\n",
    "    axes[0] = fig.add_subplot(gs[0,0:7])\n",
    "    axes[1] = fig.add_subplot(gs[0,7:])\n",
    "\n",
    "    data1=df_means.loc[grps['ChR2'],data_col]\n",
    "    data2=df_means.loc[grps['Control'],data_col]\n",
    "    \n",
    "    group1 = {'name':'ChR2',\n",
    "             'data':data1,#df_means.loc[grps['ChR2'],data_col],\n",
    "             'n':len(data1)}\n",
    "    plot1 = {'hist_kws':dict(color='blue',lw=2, ls='-')}#,bins='auto')}\n",
    "\n",
    "    group2 = {'name':'Control',\n",
    "             'data':data2,#df_means.loc[grps['Control'],data_col],\n",
    "             'n':len(data2)}\n",
    "    plot2 = {'hist_kws':dict(color='orange',lw=2, ls='-')}#,bins='auto')}\n",
    "    \n",
    "    ax = axes[0]\n",
    "    label1= f\"{group1['name']} n={group1['n']}\"\n",
    "    sns.distplot(group1['data'], label=label1,\n",
    "                 ax=ax, hist_kws=plot1['hist_kws'])\n",
    "    # ax.legend()\n",
    "\n",
    "    label2= f\"{group2['name']} n={group2['n']}\"\n",
    "    sns.distplot(group2['data'], label=label2,\n",
    "                 ax=ax,hist_kws=plot2['hist_kws'])\n",
    "    ax.legend()\n",
    "\n",
    "    \n",
    "\n",
    "    ax.axvline(group1['data'].mean(),color=plot1['hist_kws']['color'], ls='--')\n",
    "    ax.axvline(group2['data'].mean(),color=plot2['hist_kws']['color'], ls='--')\n",
    "\n",
    "\n",
    "    ax = axes[1]\n",
    "\n",
    "    ax.bar(group1['name'],group1['data'].mean(),\n",
    "          yerr=sem(group1['data']))\n",
    "\n",
    "    ax.bar(group2['name'],group2['data'].mean(),\n",
    "          yerr=sem(group2['data']))\n",
    "    \n",
    "    plt.suptitle(f\"Phase = {data_col}\",fontsize=20)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.124631Z",
     "start_time": "2020-07-01T00:53:16.406Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_assumptions(df_means,grps=None,\n",
    "                     group_col='Group',\n",
    "                     grp1='ChR2',\n",
    "                     grp2='Control',\n",
    "                     data_col='BL',\n",
    "                    plot_data=False):\n",
    "    \"\"\"MASSIVE FUNCTION PASTED IN DUE TO VERY LATE STUDY GROUP\n",
    "    WE WILL CONSTRUCT A BETTER/SIMPLER VERSION OF THIS TOGETHER IN NEXT STUDY GROUP.\"\"\"\n",
    "    \n",
    "    if grps is None:\n",
    "        grps = df_means.groupby(group_col).groups\n",
    "        \n",
    "        \n",
    "    group1 = {'name':grp1,\n",
    "              'data':df_means.loc[grps[grp1],data_col]}\n",
    "    \n",
    "    group2 = {'name':grp2,\n",
    "              'data':df_means.loc[grps[grp2],data_col]}\n",
    "    \n",
    "    results = [['Col','Test','Group(s)','Stat','p','p<.05']]\n",
    "    \n",
    "    ## Normality testing\n",
    "    stat,p = stats.normaltest(group1['data'])\n",
    "    results.append([data_col,'Normality',group1['name'],\n",
    "                  stat, p, p<.05])\n",
    "    \n",
    "    stat,p = stats.normaltest(group2['data'])    \n",
    "    results.append([data_col,'Normality',group2['name'],\n",
    "                  stat, p, p<.05])\n",
    "    ## Homo. of Variance Testing\n",
    "    stat,p = stats.levene(group1['data'],group2['data'])\n",
    "    results.append([data_col,'Equal Variance','Both',\n",
    "                  stat, p, p<.05])\n",
    "    \n",
    "    \n",
    "    ## Parametric T-Test\n",
    "    stat,p = stats.ttest_ind(group1['data'],group2['data'])\n",
    "    results.append([data_col,'T-Test 2samp','Both',stat,p,p<.05])\n",
    "    \n",
    "    ## Non-Parametric MWU\n",
    "    stat,p = stats.mannwhitneyu(group1['data'],group2['data'])\n",
    "    results.append([data_col,'Mann Whitney U','Both',stat,p,p<.05])\n",
    "    \n",
    "    ## Effect size with Cohen's d\n",
    "    d = Cohen_d(group1['data'],group2['data'])\n",
    "    results.append([data_col, \"Cohen's d\", 'Both','','',d])\n",
    "    \n",
    "#     if plot_data:\n",
    "#         plot_dists(grp, col=data_col)\n",
    "    \n",
    "    return pd.DataFrame(results[1:],columns=results[0])\n",
    "\n",
    "res = test_assumptions(df_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.125426Z",
     "start_time": "2020-07-01T00:53:16.409Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for phase in ['BL','S','PS','R']:\n",
    "    print('---'*30)\n",
    "\n",
    "    res = test_assumptions(df_means,data_col=phase)\n",
    "    display(res)\n",
    "    \n",
    "    fig,ax = plot_statplot(df_means, data_col=phase)\n",
    "    plt.show()\n",
    "\n",
    "# fig,ax = plot_dists(grp_control,grp_exp,col='R',name1='ChR2 Mice', name2='Control Mice')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSION\n",
    "- Running the correct test according to the assumptions of normality and equal variance will ensure you can get the correct test result.\n",
    "\n",
    "- Notice how the last phase (R) did NOT come back as significant when we ran the t-test, but DID come back significant when we performed the Mann Whitney U instead. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.statsmodels.org/stable/generated/statsmodels.stats.multicomp.pairwise_tukeyhsd.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvV8Knq8JVk7"
   },
   "source": [
    "## Effect Size Visual\n",
    "- https://rpsychologist.com/d3/NHST/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ephys Figure\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_pt_100719_cohort_notes/master/Images/jmi_fig1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis Pipeline\n",
    "\n",
    "1. **Test for Normality**\n",
    "    - D'Agostino-Pearson's normality test<br>\n",
    "    ```scipy.stats.normaltest```\n",
    "    - Shapiro-Wilik Test<br>\n",
    "    ```scipy.stats.shapiro```<br>\n",
    "    \n",
    "    \n",
    "2. **Test for Homogeneity of Variance**\n",
    "\n",
    "    - Levene's Test<br>\n",
    "    ```scipy.stats.levene```\n",
    "\n",
    "\n",
    "3. **Choose appropriate test based upon 1. and 2.** <br> \n",
    "    - T Test (1-sample)\n",
    "        - `stats.ttest_1samp()`\n",
    "    - T Test (2-sample)\n",
    "        - `stats.ttest_ind()`\n",
    "        - [docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)\n",
    "    - Welch's T-Test (2-sample)\n",
    "        - `stats.ttest_ind(equal_var=False)`\n",
    "        - [docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)\n",
    "        \n",
    "    - Mann Whitney U\n",
    "        - `stats.mannwhitneyu()`\n",
    "        - [docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)\n",
    "    - ANOVA \n",
    "        - `stats.f_oneway()`\n",
    "        - [docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html)\n",
    "    - Tukey's\n",
    "     - `statsmodels.stats.multicomp.pairwise_tukeyhsd`\n",
    "     -[docs](https://www.statsmodels.org/stable/generated/statsmodels.stats.multicomp.pairwise_tukeyhsd.html)\n",
    "    \n",
    "\n",
    "4. **Calculate effect size for significant results.**\n",
    "    - Effect size: [cohen's d](https://stackoverflow.com/questions/21532471/how-to-calculate-cohens-d-in-python)\n",
    "    - Interpretation:\n",
    "        - Small effect = 0.2 ( cannot be seen by naked eye)\n",
    "        - Medium effect  = 0.5\n",
    "        - Large Effect = 0.8 (can be seen by naked eye)\n",
    "        \n",
    "5. **If significant, follow up with post-hoc tests (if have more than 2 groups)**\n",
    "    - [Tukey's](https://www.statsmodels.org/stable/generated/statsmodels.stats.multicomp.pairwise_tukeyhsd.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:24.126286Z",
     "start_time": "2020-07-01T00:53:16.414Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def test_assumptions(df_means,grps=None,\n",
    "#                      group_col='Group',\n",
    "#                      grp1='ChR2',\n",
    "#                      grp2='Control',\n",
    "#                      data_col='BL'):\n",
    "    \n",
    "#     if grps is None:\n",
    "#         grps = df_means.groupby(group_col).groups\n",
    "        \n",
    "        \n",
    "#     group1 = {'name':grp1,\n",
    "#               'data':df_means.loc[grps[grp1],data_col]}\n",
    "    \n",
    "#     group2 = {'name':grp2,\n",
    "#               'data':df_means.loc[grps[grp2],data_col]}\n",
    "    \n",
    "#     results = [['Col','Test','Group(s)','Stat','p','p<.05']]\n",
    "    \n",
    "#     ## Normality testing\n",
    "#     stat,p = stats.normaltest(group1['data'])\n",
    "#     results.append([data_col,'Normality',group1['name'],\n",
    "#                   stat, p, p<.05])\n",
    "    \n",
    "#     stat,p = stats.normaltest(group2['data'])    \n",
    "#     results.append([data_col,'Normality',group2['name'],\n",
    "#                   stat, p, p<.05])\n",
    "#     ## Homo. of Variance Testing\n",
    "#     stat,p = stats.levene(group1['data'],group2['data'])\n",
    "#     results.append([data_col,'Equal Variance','Both',\n",
    "#                   stat, p, p<.05])\n",
    "    \n",
    "#     ## Parametric T-Test\n",
    "#     stat,p = stats.ttest_ind(group1['data'],group2['data'])\n",
    "#     results.append([data_col,'T-Test 2samp','Both',stat,p,p<.05])\n",
    "    \n",
    "#     ## Non-Parametric MWU\n",
    "#     stat,p = stats.mannwhitneyu(group1['data'],group2['data'])\n",
    "#     results.append([data_col,'Mann Whitney U','Both',stat,p,p<.05])\n",
    "    \n",
    "#     ## Effect size with Cohen's d\n",
    "#     d = Cohen_d(group1['data'],group2['data'])\n",
    "#     results.append([data_col, \"Cohen's d\", 'Both','','',d])\n",
    "    \n",
    "#     return pd.DataFrame(results[1:],columns=results[0])\n",
    "\n",
    "# test_assumptions(df_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NORMALIZING ALL LICKS TO AVERAGE OF 4 BASELINE DAYS [NEW 06/29]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:07:10.267135Z",
     "start_time": "2020-07-01T01:07:10.263169Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_df_to_pivot(df_,phase_dict):\n",
    "    ## MELTING THE DATA INTO FORM WORKABLE FOR PLOTS/ANALYSIS\n",
    "    df2 = pd.melt(df_.reset_index(),id_vars=['Mouse_ID','Group','Sex'],\n",
    "                  value_name='Licks',var_name='Day')\n",
    "    df2['Phase'] = df2['Day'].map(phase_dict)\n",
    "    df2['Day_of_Phase'] = df2['Day'].apply(lambda x: x[-1])\n",
    "    df2 = df2.dropna(subset=['Phase'])\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T01:00:39.090626Z",
     "start_time": "2020-07-01T01:00:39.084792Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate average of BL days for each mouse\n",
    "baseline_lick_avgs = df[BL_cols].mean(axis=1)\n",
    "baseline_lick_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:22.745289Z",
     "start_time": "2020-07-01T00:53:22.684276Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_norm = df.copy()#select_dtypes('number')#.applymap(lambda x:x/baseline_lick_avgs)\n",
    "## NORMALIZING ALL LICKS TO AVERAGE OF 4 BASELINE DAYS\n",
    "for col in df_norm.select_dtypes('number').columns:\n",
    "    df_norm[col] = df_norm[col] / baseline_lick_avgs\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T00:53:22.838106Z",
     "start_time": "2020-07-01T00:53:22.803266Z"
    }
   },
   "outputs": [],
   "source": [
    "df2_norm = process_df_to_pivot(df_norm,phase_dict)\n",
    "df2_norm"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sect 18+19  with Titanic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env]",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "360.85px",
    "left": "630px",
    "right": "20px",
    "top": "38px",
    "width": "480px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
